{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc78914b",
   "metadata": {},
   "source": [
    "# Учебный проект 17_Разработка системы компьютерного зрения для определения возраста покупателей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37300d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Содержание\n",
    "\n",
    "* [Описание проекта](#Описание)\n",
    "* [Импорт библиотек Python](#Импорт)\n",
    "* [Загрузка данных](#Загрузка)\n",
    "* [Построение модели машинного обучения](#Моделирование)\n",
    "* [Общий вывод](#Вывод)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4907c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Описание проекта <a class = 'anchor' id = 'Описание'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ffff3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "На исследовании находятся данные с `фотографиями покупателей и их возрасте`, которые были предоставлены руководством компании \"Хлеб-Соль\".\n",
    "\n",
    "---\n",
    "\n",
    "`Задача`\n",
    "\n",
    "Разработать модель машинного обучения для **вычисления приблизительного возраста покупателей** с целью:\n",
    "* анализа покупок и предложения товаров для возрастных групп;\n",
    "* контроля добросовестности кассиров при продаже алкоголя.\n",
    "\n",
    "Необходимо добиться максимально возможной **низкой MAE**.\n",
    "\n",
    "---\n",
    "\n",
    "`Описание данных`\n",
    "\n",
    "* папка `/datasets/faces/` с фотографиями;\n",
    "* файл `CSV` с разметкой, содержащий два столбца:\n",
    "    * `file_name` — название файла фотографии;\n",
    "    * `real_age` — возраст человека на фотографии\n",
    "\n",
    "---\n",
    "\n",
    "`Путь решения`\n",
    "\n",
    "1. Собрать исторические данные о покупателях магазина;\n",
    "2. Провести предобработку значений в наборе данных;\n",
    "3. Провести исследовательский анализ для проектирования модели:\n",
    "    * Изучить размер выборки;\n",
    "    * Построить график распределения возраста в выборке;\n",
    "    * Вывести на экран 10-15 фотографий покупателей и изучить структуру датасета.\n",
    "4. Построить модель машинного обучения для вычисления приблизительного возраста покупателей с перебором различных параметров и конфигураций;\n",
    "5. Сформировать вывод о подготовленных решениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48236228",
   "metadata": {},
   "source": [
    "## Импорт библиотек Python <a class = 'anchor' id = 'Импорт'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe75c0",
   "metadata": {},
   "source": [
    "Данный блок характеризуется следующими последовательными действиями:\n",
    "1. Импорт библиотек Python:\n",
    "    * для манипулирования данными;\n",
    "    * для визуализации данных;\n",
    "    * для решения задач машинного обучения:\n",
    "        * инструменты проектирования нейронных сетей для анализа изображений;\n",
    "        * метрики оценки эффективности моделей;\n",
    "        * механизмы отключения предупреждений.\n",
    "2. Инициализация переменных-констант для последующего использования на этапе построения моделей МО;\n",
    "3. Формирование вывода по итогам данного этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c5182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (2.20.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (6.33.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (3.13.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.1)\n",
      "Requirement already satisfied: namex in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: pillow in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\k.storozhuk\\desktop\\yandexpraktikum_projects\\.py_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb274c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек python\n",
    "\n",
    "# для манипулирования данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# для визуализации данных\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# инструменты проектирования нейронных сетей для анализа изображений\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "\n",
    "# игнорирование возможных предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7813a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация констант для дальнейшего использования в проекте\n",
    "# инициализация переменной SEED для фиксирования случайности\n",
    "# инициализация переменной TEST_SIZE для фиксирования размера тестовой выборки при разбиении наборов данных\n",
    "SEED = 12345\n",
    "TEST_SIZE = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b4e01",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "1. Импортированы библиотеки Python:\n",
    "    * для манипулирования данными:\n",
    "        * pandas;\n",
    "        * numpy.\n",
    "    * для визуализации данных:\n",
    "        * matplotlib.pyplot;\n",
    "        * seaborn.\n",
    "    * для решения задач машинного обучения:\n",
    "        * инструменты проектирования нейронных сетей для анализа изображений;\n",
    "        * метрики оценки эффективностей модели:\n",
    "            * mean_absolute_error - средняя абсолютная ошибка.\n",
    "    * для отключения предупреждений.\n",
    "2. Инициализированы переменные:\n",
    "    * **TEST_SIZE** для фиксирования размера тестовой выборки при разбиении наборов данных;\n",
    "    * **SEED** для фиксирования случайности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41555e96",
   "metadata": {},
   "source": [
    "## Загрузка данных <a class = 'anchor' id = 'Загрузка'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d93a2",
   "metadata": {},
   "source": [
    "Данный блок характеризуется следующими последовательными действиями:\n",
    "\n",
    "1. Загрузка данных в рабочую среду Jupyter Notebook - инициализация переменной `datagen` для загрузки данных из директории с изображениями;\n",
    "2. Вывод на экран размерности выборок:\n",
    "    * тренировочной - инициализация переменной datagen_flow_train;\n",
    "    * валидационной - инициализация переменной datagen_flow_test.\n",
    "3. Загрузка данных из файла `CSV` с разметкой;\n",
    "4. Вывод на экран общей информации о наборе данных:\n",
    "    * вывод общей структуры набора данных - демонстрация первых 5 строк;\n",
    "    * общей информации о наборе данных;\n",
    "    * распределение количественных величин в наборе данных.\n",
    "5. Формирование вывода по итогам данного этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных в рабочую среду Jupyter Notebook\n",
    "\n",
    "# инициализация переменной datagen для загрузки данных из директории с изображениями\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             validation_split=TEST_SIZE,\n",
    "                             horizontal_flip = True,\n",
    "                             vertical_flip = True,\n",
    "                             rotation_range=90)\n",
    "\n",
    "# инициализация переменной datagen_flow_train\n",
    "datagen_flow_train = datagen.flow_from_directory(\n",
    "    '/datasets/faces/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=SEED)\n",
    "\n",
    "# инициализация переменной datagen_flow_test\n",
    "datagen_flow_test = datagen.flow_from_directory(\n",
    "    '/datasets/faces/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных из файла CSV с разметкой\n",
    "labels = pd.read_csv('/datasets/faces/labels.csv')\n",
    "\n",
    "# инициализация пользовательской функции для первичного изучения содержимого наборов данных\n",
    "def first_meeting (df : pd.DataFrame, df_name : str) -> None:\n",
    "    print(f'Структура набора данных {df_name}')\n",
    "    display(df.head())\n",
    "    print('Общая информация о наборе')\n",
    "    print(df.info())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывод на экран структуры и основных параметров датасета\n",
    "first_meeting(labels, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация пользовательской функции построения распределений количественных непрерывных показателей\n",
    "def num_distribution(df : pd.DataFrame, column : str, bins : int):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.xlabel(f'Значения признака {column}')\n",
    "    plt.ylabel(f'Частота значений признака')\n",
    "    plt.title(f'Гистограмма значений {column}', fontsize = 10)\n",
    "    sns.histplot(data = df, x = df[column], bins = bins)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.xlabel(f'Значения признака {column}')\n",
    "    plt.title(f'Диаграмма размаха значений {column}', fontsize = 10)\n",
    "    sns.boxplot(data = df, x = df[column])\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация пользовательской функции по построению гистограмм по передаваемым метрикам\n",
    "def histogram_plotting(data: pd.DataFrame, feature : str, bins: int, x_size: int, y_size: int, feature_xlabel : str):\n",
    "    # вычисление статистических метрик для дальнейшей визуализации\n",
    "    q1 = data[feature].quantile(0.25)\n",
    "    q3 = data[feature].quantile(0.75)\n",
    "    upper_bound = q3 + 1.5 * (q3 - q1)\n",
    "    lower_bound = q1 - 1.5 * (q3 - q1)\n",
    "\n",
    "    # построение визуализации\n",
    "    plt.figure(figsize = (x_size, y_size))\n",
    "    plt.hist(data[feature], color = 'blue', edgecolor = 'white', bins = bins)\n",
    "    plt.axvline(upper_bound, c = 'red', ls = '-', label = 'верхняя граница допустимых значений')\n",
    "    plt.axvline(q3, c = 'red', ls = '--', label = '3 квартиль значений')\n",
    "    plt.axvline(q1, c = 'black', ls = '--', label = '1 квартиль значений')\n",
    "    plt.axvline(lower_bound, c = 'black', ls = '-', label = 'нижняя граница допустимых значений')\n",
    "    plt.title(f'Гистограмма распределения значений по метрике: {feature_xlabel}', fontsize = 10)\n",
    "    plt.xlabel(feature_xlabel)\n",
    "    plt.ylabel('Количество значений по метрике')\n",
    "    plt.legend(bbox_to_anchor = (1, 0.6))\n",
    "    plt.show()\n",
    "\n",
    "    # вывод статистических метрик на экран\n",
    "    print('Верхняя допустимая граница значений:', upper_bound)\n",
    "    print('Нижняя допустимая граница значений:', lower_bound)\n",
    "    print('Медианное значение:', data[feature].median())\n",
    "    print('Среднее значение:', round(data[feature].mean(), 2))\n",
    "\n",
    "    # расчет доли аномальных значений по метрике\n",
    "    print('Доля значений, выходящих за верхнюю границу: {:.2%}'.format(data[data[feature] > upper_bound].shape[0] / data[feature].shape[0]))\n",
    "    print('Доля значений, выходящих за нижнюю границу: {:.2%}'.format(data[data[feature] < lower_bound].shape[0] / data[feature].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6462c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлечение батча данных и разбиение на признаки и классы изображений\n",
    "features, target = next(datagen_flow_train)\n",
    "\n",
    "# выводим 16 изображений\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    fig.add_subplot(4, 4, i+1)\n",
    "    plt.imshow(features[i])\n",
    "    # для компактности удаляем оси и прижимаем изображения друг к другу\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ebf98e",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "1. Произведена загрузка данных в рабочую среду Jupyter Notebook. Инициализирована переменная `datagen`. Набор данных состоит из 7_591 изображений;\n",
    "2. Произведено разделение исходного набора на выборки:\n",
    "    * `datagen_flow_train` - обучающая выборка;\n",
    "    * `datagen_flow_test` - тестовая выборка.\n",
    "3. Выведены на экран основные параметры набора данных `labels`:\n",
    "    * набор данных состоит из 2 столбцов и 7591 строк;\n",
    "    * в наборе отсутствуют пропущенные значения.\n",
    "4. Выведены на экран основные параметры распределения данных по признаку `real_age`:\n",
    "    * распределение имеет вид, приближенный к нормальному, с небольшим скосом вправо. Стоит отметить, что в наборе присутствуют так же слишком юные покупатели - дети;\n",
    "    * присутствуют выбросы в виде аномально больших значений - их доля составляет 2.23% от всего набора;\n",
    "    * медианное значение возраста покупателей - 29 лет;\n",
    "    * средний возраст покупателей - 31.2 лет.\n",
    "\n",
    "В целом, набор данных не требует дополнительных преобразований помимо тех, что уже были выполнены на этапе загрузки.\n",
    "При построении модели нейронной сети и при дальнейшем получении прогнозов будем учитывать, что в наборе присутствуют аномальные значения. А значит, итоговые прогнозные значения могут быть выше, чем реальный возраст покупателей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b1da5",
   "metadata": {},
   "source": [
    "## Построение модели машинного обучения <a class = 'anchor' id = 'Моделирование'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53564fe",
   "metadata": {},
   "source": [
    "Данный блок характеризуется следующими последовательными действиями:\n",
    "\n",
    "1. Построение модели нейронной сети с инициализацией пользовательских функций:\n",
    "    * load_train - загрузка обучающего набора данных;\n",
    "    * load_test - загрузка тестового набора данных;\n",
    "    * create_model - создание модели нейронной сети;\n",
    "    * train_model - обучение модели нейронной сети.\n",
    "2. Формирование вывода по итогам данного этапа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f52326",
   "metadata": {},
   "source": [
    "**Код, приведенный ниже, прошел предварительное исполнение на отдельном GPU-тренажере**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ddcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция загрузки обучающей выборки\n",
    "def load_train(path):\n",
    "    labels = pd.read_csv(\"/datasets/faces/labels.csv\")\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        vertical_flip=True,\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1.0 / 255,\n",
    "        validation_split=TEST_SIZE,\n",
    "    )\n",
    "\n",
    "    train_datagen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=\"/datasets/faces/final_files/\",\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"real_age\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode=\"raw\",\n",
    "        subset=\"training\",\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    return train_datagen_flow\n",
    "\n",
    "\n",
    "# функция загрузки валидационной выборки\n",
    "def load_test(path):\n",
    "    labels = pd.read_csv(\"/datasets/faces/labels.csv\")\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        validation_split=TEST_SIZE,\n",
    "        rescale=1.0 / 255)\n",
    "\n",
    "    test_datagen_flow = test_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=\"/datasets/faces/final_files/\",\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"real_age\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode=\"raw\",\n",
    "        subset=\"validation\",\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    return test_datagen_flow\n",
    "\n",
    "\n",
    "# функция создания модели нейронной сети\n",
    "def create_model(input_shape):\n",
    "    # импортируем архитектуру ResNet\n",
    "    backbone = ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        weights=\"/datasets/keras_models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "        include_top=False,\n",
    "    )\n",
    "    # инициализация модели\n",
    "    model = Sequential()\n",
    "    # добавление слоёв в модель\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation=\"relu\"))\n",
    "    # подготовка модели к обучению\n",
    "    optimizer = Adam(learning_rate = 0.00005)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    # результат: возвращение настроенной модели\n",
    "    return model\n",
    "\n",
    "\n",
    "# функция обучения модели\n",
    "def train_model(\n",
    "    model,\n",
    "    train_datagen_flow,\n",
    "    test_datagen_flow,\n",
    "    batch_size=None,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "):\n",
    "\n",
    "    model.fit(\n",
    "        train_datagen_flow,\n",
    "        validation_data=test_datagen_flow,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        verbose=2,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffe73d",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "source": [
    "**Скопирован результат исполнения кода в отдельном GPU-тренажере**\n",
    "\n",
    "\n",
    "```Train for 178 steps, validate for 60 steps\n",
    "Epoch 1/20\n",
    "178/178 - 99s - loss: 399.3076 - mean_absolute_error: 14.9709 - val_loss: 615.4288 - val_mean_absolute_error: 19.8011\n",
    "Epoch 2/20\n",
    "178/178 - 92s - loss: 145.7714 - mean_absolute_error: 9.2002 - val_loss: 804.7238 - val_mean_absolute_error: 23.4426\n",
    "Epoch 3/20\n",
    "178/178 - 92s - loss: 126.4676 - mean_absolute_error: 8.5357 - val_loss: 403.6989 - val_mean_absolute_error: 15.0621\n",
    "Epoch 4/20\n",
    "178/178 - 92s - loss: 113.5236 - mean_absolute_error: 8.0955 - val_loss: 178.7277 - val_mean_absolute_error: 10.0013\n",
    "Epoch 5/20\n",
    "178/178 - 92s - loss: 102.9207 - mean_absolute_error: 7.7567 - val_loss: 147.3729 - val_mean_absolute_error: 9.0171\n",
    "Epoch 6/20\n",
    "178/178 - 92s - loss: 95.1175 - mean_absolute_error: 7.4542 - val_loss: 96.8540 - val_mean_absolute_error: 7.4767\n",
    "Epoch 7/20\n",
    "178/178 - 92s - loss: 88.7458 - mean_absolute_error: 7.1451 - val_loss: 92.6042 - val_mean_absolute_error: 7.2815\n",
    "Epoch 8/20\n",
    "178/178 - 92s - loss: 82.3103 - mean_absolute_error: 6.9123 - val_loss: 92.7663 - val_mean_absolute_error: 7.3931\n",
    "Epoch 9/20\n",
    "178/178 - 93s - loss: 78.4509 - mean_absolute_error: 6.7620 - val_loss: 104.8380 - val_mean_absolute_error: 7.7020\n",
    "Epoch 10/20\n",
    "178/178 - 92s - loss: 73.2345 - mean_absolute_error: 6.5186 - val_loss: 99.7994 - val_mean_absolute_error: 7.3209\n",
    "Epoch 11/20\n",
    "178/178 - 92s - loss: 67.0615 - mean_absolute_error: 6.3234 - val_loss: 108.0002 - val_mean_absolute_error: 7.6862\n",
    "Epoch 12/20\n",
    "178/178 - 92s - loss: 64.7014 - mean_absolute_error: 6.1460 - val_loss: 110.9409 - val_mean_absolute_error: 7.7313\n",
    "Epoch 13/20\n",
    "178/178 - 92s - loss: 59.8807 - mean_absolute_error: 5.9705 - val_loss: 94.1817 - val_mean_absolute_error: 7.3128\n",
    "Epoch 14/20\n",
    "178/178 - 92s - loss: 59.2435 - mean_absolute_error: 5.9159 - val_loss: 94.7431 - val_mean_absolute_error: 7.3108\n",
    "Epoch 15/20\n",
    "178/178 - 92s - loss: 54.1986 - mean_absolute_error: 5.6681 - val_loss: 84.1356 - val_mean_absolute_error: 7.0009\n",
    "Epoch 16/20\n",
    "178/178 - 92s - loss: 52.8570 - mean_absolute_error: 5.5886 - val_loss: 91.8597 - val_mean_absolute_error: 7.1832\n",
    "Epoch 17/20\n",
    "178/178 - 92s - loss: 50.1566 - mean_absolute_error: 5.4451 - val_loss: 94.5077 - val_mean_absolute_error: 7.3152\n",
    "Epoch 18/20\n",
    "178/178 - 92s - loss: 48.3286 - mean_absolute_error: 5.4123 - val_loss: 105.5588 - val_mean_absolute_error: 7.5545\n",
    "Epoch 19/20\n",
    "178/178 - 92s - loss: 47.1229 - mean_absolute_error: 5.2773 - val_loss: 87.3449 - val_mean_absolute_error: 6.9815\n",
    "Epoch 20/20\n",
    "178/178 - 92s - loss: 44.8868 - mean_absolute_error: 5.1817 - val_loss: 92.2197 - val_mean_absolute_error: 7.2710\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "60/60 - 9s - loss: 92.2197 - mean_absolute_error: 7.2710\n",
    "Test MAE: 7.2710\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6c779",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "1. Построена модель нейронной сети для анализа изображений покупателей. Инициализированы пользовательские функции:\n",
    "    * load_train - загрузка обучающего набора данных;\n",
    "    * load_test - загрузка тестового набора данных;\n",
    "    * create_model - создание модели нейронной сети;\n",
    "    * train_model - обучение модели нейронной сети.\n",
    "2. По результатам обучения модели на GPU-тренажере, удалось достичь целевого значения метрики `MAE` - 7.2710."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a106a1",
   "metadata": {},
   "source": [
    "## Общий вывод <a class = 'anchor' id = 'Вывод'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ece918",
   "metadata": {},
   "source": [
    "1. Импортированы библиотеки Python:\n",
    "    * для манипулирования данными:\n",
    "        * pandas;\n",
    "        * numpy.\n",
    "    * для визуализации данных:\n",
    "        * matplotlib.pyplot;\n",
    "        * seaborn.\n",
    "    * для решения задач машинного обучения:\n",
    "        * инструменты проектирования нейронных сетей для анализа изображений.\n",
    "    * для отключения предупреждений.\n",
    "2. Инициализированы переменные:\n",
    "    * **TEST_SIZE** для фиксирования размера тестовой выборки при разбиении наборов данных;\n",
    "    * **SEED** для фиксирования случайности.\n",
    "3. Произведена загрузка данных в рабочую среду Jupyter Notebook. Инициализирована переменная `datagen`. Набор данных состоит из 7_591 изображений;\n",
    "4. Произведено разделение исходного набора на выборки:\n",
    "    * `datagen_flow_train` - обучающая выборка;\n",
    "    * `datagen_flow_test` - тестовая выборка.\n",
    "5. Выведены на экран основные параметры набора данных `labels`:\n",
    "    * набор данных состоит из 2 столбцов и 7591 строк;\n",
    "    * в наборе отсутствуют пропущенные значения.\n",
    "6. Выведены на экран основные параметры распределения данных по признаку `real_age`:\n",
    "    * распределение имеет вид, приближенный к нормальному, с небольшим скосом вправо. Стоит отметить, что в наборе присутствуют так же слишком юные покупатели - дети;\n",
    "    * присутствуют выбросы в виде аномально больших значений - их доля составляет 2.23% от всего набора;\n",
    "    * медианное значение возраста покупателей - 29 лет;\n",
    "    * средний возраст покупателей - 31.2 лет.\n",
    "\n",
    "В целом, набор данных не требует дополнительных преобразований помимо тех, что уже были выполнены на этапе загрузки.\n",
    "При построении модели нейронной сети и при дальнейшем получении прогнозов будем учитывать, что в наборе присутствуют аномальные значения. А значит, итоговые прогнозные значения могут быть выше, чем реальный возраст покупателей.\n",
    "\n",
    "7. Построена модель нейронной сети для анализа изображений покупателей. Инициализированы пользовательские функции:\n",
    "    * load_train - загрузка обучающего набора данных;\n",
    "    * load_test - загрузка тестового набора данных;\n",
    "    * create_model - создание модели нейронной сети;\n",
    "    * train_model - обучение модели нейронной сети.\n",
    "8. По результатам обучения модели на GPU-тренажере, удалось достичь целевого значения метрики `MAE` - 7.2710.\n",
    "\n",
    "Модель неплохо справилась с задачей - поставленная цель была достигнута. Улучшить качество прогноза можно путем дополнительных преобразований набора данных и усложнения нейронной сети. Также глобально можно было бы дополнить набор данных большим количеством фотографий."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
